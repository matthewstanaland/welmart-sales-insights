from pyspark.sql import SparkSession
from pyspark.sql.functions import sum, count, year, col

# âœ… Initialize Spark Session
spark = SparkSession.builder.appName("Welmart Sales Analysis").getOrCreate()

# âœ… Load dataset (Ensure 'Superstore.csv' is in the same folder)
file_path = "Superstore.csv"
df = spark.read.csv(file_path, header=True, inferSchema=True)

# âœ… Print Schema (For Debugging)
df.printSchema()

# âœ… Best-selling product sub-category
best_selling_sub_category = (
    df.groupBy("Sub-Category")
    .agg(sum("Quantity").alias("Total_Quantity"))
    .orderBy("Total_Quantity", ascending=False)
    .first()["Sub-Category"]
)

# âœ… Product category generating the highest revenue
highest_revenue_category = (
    df.groupBy("Category")
    .agg(sum("Sales").alias("Total_Sales"))
    .orderBy("Total_Sales", ascending=False)
    .first()["Category"]
)

# âœ… State with highest number of orders
state_with_most_orders = (
    df.groupBy("State")
    .agg(count("*").alias("Order_Count"))
    .orderBy("Order_Count", ascending=False)
    .first()["State"]
)

# âœ… Year with highest revenue
df = df.withColumn("Year", year(df["Order Date"]))
highest_revenue_year = (
    df.groupBy("Year")
    .agg(sum("Sales").alias("Total_Sales"))
    .orderBy("Total_Sales", ascending=False)
    .first()["Year"]
)

# âœ… Top 10 most valuable customers
top_customers = (
    df.groupBy("Customer ID")
    .agg(sum("Sales").alias("Total_Sales"))
    .orderBy("Total_Sales", ascending=False)
    .limit(10)
)

# âœ… Check if 'Order Type' column exists
if 'Order Type' in df.columns:
    # âœ… Analysis based on order types (single or bulk)
    order_type_analysis = (
        df.groupBy("Order Type")
        .agg(sum("Sales").alias("Total_Sales"), count("*").alias("Order_Count"))
        .orderBy("Total_Sales", ascending=False)
    )
    print("\nğŸ“Š Order Type Analysis:")
    order_type_analysis.show()
else:
    print("\nâš ï¸ 'Order Type' column not found in the dataset.")

# âœ… Analysis based on customer demographics (e.g., segment)
customer_segment_analysis = (
    df.groupBy("Segment")
    .agg(sum("Sales").alias("Total_Sales"), count("*").alias("Order_Count"))
    .orderBy("Total_Sales", ascending=False)
)

# âœ… Analysis based on shipping modes
shipping_mode_analysis = (
    df.groupBy("Ship Mode")
    .agg(sum("Sales").alias("Total_Sales"), count("*").alias("Order_Count"))
    .orderBy("Total_Sales", ascending=False)
)

# âœ… Print Results
print("\nğŸ”¹ Best-selling product sub-category:", best_selling_sub_category)
print("ğŸ”¹ Product category generating highest revenue:", highest_revenue_category)
print("ğŸ”¹ State with highest number of orders:", state_with_most_orders)
print("ğŸ”¹ Year with highest revenue:", highest_revenue_year)

print("\nğŸ† Top 10 Most Valuable Customers:")
top_customers.show()

print("\nğŸ“Š Customer Segment Analysis:")
customer_segment_analysis.show()

print("\nğŸ“Š Shipping Mode Analysis:")
shipping_mode_analysis.show()

print("\nâœ… Welmart analysis completed successfully!")

# âœ… Stop Spark Session
spark.stop()
